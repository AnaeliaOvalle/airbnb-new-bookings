library(tree)
library(ISLR)
attach(Carseats)
High = ifelse(Sales<=8, "No", "Yes")
Carseats = data.frame(Carseats, High)
tree.carseats = tree(High~.-Sales, Carseats)
summary(tree.carseats)
set.seed(2)
train = sample(1:nrow(Carseats), 200)
Carseats.test = Carseats[-train,]
High.test = High[-train]
tree.carseats = tree(High~.-Sales, Carseats, subset = train)
tree.pred = predict(tree.carseats, Carseats.test, type = 'class')
table(tree.pred, High.test)
View(Carseats)
set.seed(2)
#a) split into train and test
train = sample(1:nrow(Carseats), 200)
test = Carseats[-train,]
tree.carseats = tree(Sales~., Carseats, subset = train)
tree.pred = predict(tree.carseats, test, type = 'class')
tree.pred = predict(tree.carseats, test)
table(tree.pred, test$Sales)
plot(tree.carseats)
text(tree.carseats, pretty = 0)
par(mfrow = c(1,1))
plot(tree.carseats)
text(tree.carseats, pretty = 0)
text(tree.carseats, pretty = 1)
?text(tree.carseats, pretty = 1)
plot(tree.carseats)
text(tree.carseats, pretty = 0, cex = 0.5)
plot(tree.carseats)
text(tree.carseats, pretty = 0, cex = 0.3)
plot(tree.carseats)
text(tree.carseats, pretty = 0, cex = 0.4)
plot(tree.carseats)
text(tree.carseats, pretty = 0, cex = 0.5)
plot(tree.carseats)
text(tree.carseats, cex = 0.5)
plot(tree.carseats)
text(tree.carseats, pretty =0, cex = 0.5)
mean((tree.pred - test$Sales)^2)
cv.carseats = cv.tree(tree.carseats)
plot(cv.carseats, cv.boston$dev, type = 'b')
plot(cv.carseats, cv.carseats$dev, type = 'b')
cv.carseats = cv.tree(tree.carseats)
plot(cv.carseats, cv.carseats$dev, type = 'b')
?plot
names(cv.carseats)
plot(cv.carseats, cv.carseats$dev)
plot(cv.carseats, cv.carseats$dev, xlim = 100)
plot(cv.carseats, cv.carseats$dev, type = 'b', xlim = c(1,100))
timeline = c(-20, 20)
plot(cv.carseats, cv.carseats$dev, type = 'b', xlim = timeline)
plot(cv.carseats, cv.carseats$dev, type = "b", xlim = timeline)
plot(cv.carseats, cv.carseats$dev)
plot(cv.carseats, cv.carseats$dev,xlim = timeline)
plot(cv.carseats,xlim = timeline)
plot(cv.carseats$size, cv.carseats$dev,xlim = timeline)
names(cv.carseats)
plot(cv.carseats$size, cv.carseats$dev)
plot(cv.carseats$size, cv.carseats$dev, type = 'b')
prune.carseats = prune.tree(tree.carseats, best = 4)
prune.carseats = prune.tree(tree.carseats, best = 4)
plot(prune.carseats)
text(prune.carseats, pretty = 0, cex = 0.5)
mean((prune.carseats- test$Sales)^2)
prune.carseats
tree.carseats
tree.prune.pred = predict(prune.carseats, test)
mean((tree.prune.pred - test$Sales)^2)
length(col(Carseats))
length(colnames(Carseats))
bag.carseats = randomForest(Sales~., data = Carseats, subset = train, mtry = length(colnames(Carseats)), importance = T)
bag.carseats = randomForest(Sales~., data = Carseats, subset = train, mtry = 12, importance = T)
dim(Carseats)
bag.carseats = randomForest(Sales~., data = Carseats, subset = train, mtry = length(colnames(Carseats))-1, importance = T)
bag.carseats
pred.bag = predict(bag.carseats, newdata = test)
plot(pred.bag, test)
pred.bag = predict(bag.carseats, newdata = test$Sales)
plot(pred.bag, test)
pred.bag = predict(bag.carseats, newdata = test$Sales)
pred.bag = predict(bag.carseats, newdata = test)
plot(pred.bag, test$Sales)
importance(bag.carseats)
library(tree)
library(ISLR)
attach(Carseats)
library(tree)
library(ISLR)
attach(Carseats)
par(mfrow = c(1,1))
#a) split into train and test
train = sample(1:nrow(Carseats), 200)
test = Carseats[-train,]
#b) test MSE: 2.57
tree.carseats = tree(Sales~., Carseats, subset = train)
tree.pred = predict(tree.carseats, test)
mean((tree.pred - test$Sales)^2)
plot(tree.carseats)
text(tree.carseats, pretty = 0, cex = 0.5)
#b) test MSE: 5.11387
tree.carseats = tree(Sales~., Carseats, subset = train)
tree.pred = predict(tree.carseats, test)
mean((tree.pred - test$Sales)^2)
plot(tree.carseats)
text(tree.carseats, pretty = 0, cex = 0.5)
#c)
cv.carseats = cv.tree(tree.carseats)
names(cv.carseats)
timeline = c(-20, 20)
plot(cv.carseats$size, cv.carseats$dev, type = 'b')
# it looks like the best number of trees is 4, so we prune down!
names(cv.carseats)
names(cv.carseats)
names(cv.carseats)
plot(cv.carseats$size, cv.carseats$dev, type = 'b')
prune.carseats = prune.tree(tree.carseats, best = 13)
plot(prune.carseats)
text(prune.carseats, pretty = 0, cex = 0.5)
tree.prune.pred = predict(prune.carseats, test)
mean((tree.prune.pred - test$Sales)^2)
library(randomForest)
set.seed(1)
length(colnames(Carseats))
bag.carseats = randomForest(Sales~., data = Carseats, subset = train, mtry = length(colnames(Carseats))-1, importance = T)
bag.carseats = randomForest(Sales~., data = Carseats, subset = train, mtry = length(colnames(Carseats)), importance = T)
bag.carseats = randomForest(Sales~., data = Carseats, subset = train, mtry = length(colnames(Carseats))-1, importance = T)
pred.bag = predict(bag.carseats, newdata = test)
plot(pred.bag, test$Sales)
importance(bag.carseats)
varImpPlot(bag.carseats)
order(importance(bag.carseats))
importance(order(bag.carseats))
mean((pred.bag - test$Sales)^2)
importance(bag.carseats)
rf.carseats = randomForest(Sales~., data = Carseats, subset = train, mtry = 6, importance = T)
pred.rf = predict(rf.carseats, newdata = test)
mean((pred.rf - test$Sales)^2)
plot(pred.rf, test$Sales)
importance(rf.carseats)
varImpPlot(rf.carseats)
tree.carseats
summary(tree.carseats)
train = sample(1:nrow(Carseats), nrow(Carseats) / 2)
test = Carseats[-train,]
#b) test MSE: 5.11387
tree.carseats = tree(Sales~., Carseats, subset = train)
summary(tree.carseats)
tree.pred = predict(tree.carseats, test)
mean((tree.pred - test$Sales)^2)
plot(tree.carseats)
text(tree.carseats, pretty = 0, cex = 0.5)
#c)
cv.carseats = cv.tree(tree.carseats)
names(cv.carseats)
plot(cv.carseats$size, cv.carseats$dev, type = 'b')
prune.carseats = prune.tree(tree.carseats, best = 14)
plot(prune.carseats)
text(prune.carseats, pretty = 0, cex = 0.5)
tree.prune.pred = predict(prune.carseats, test)
mean((tree.prune.pred - test$Sales)^2)
train = sample(1:nrow(Carseats), nrow(Carseats) / 2)
test = Carseats[-train,]
#b) test MSE: 5.16
tree.carseats = tree(Sales~., Carseats, subset = train)
summary(tree.carseats)
tree.pred = predict(tree.carseats, test)
mean((tree.pred - test$Sales)^2)
tree.carseats = tree(Sales~., Carseats, subset = train)
summary(tree.carseats)
tree.pred = predict(tree.carseats, test)
mean((tree.pred - test$Sales)^2)
cv.carseats = cv.tree(tree.carseats)
names(cv.carseats)
plot(cv.carseats$size, cv.carseats$dev, type = 'b')
prune.carseats = prune.tree(tree.carseats, best = 13)
plot(prune.carseats)
text(prune.carseats, pretty = 0, cex = 0.5)
tree.prune.pred = predict(prune.carseats, test)
mean((tree.prune.pred - test$Sales)^2)
prune.carseats = prune.tree(tree.carseats, best = 12)
plot(prune.carseats)
text(prune.carseats, pretty = 0, cex = 0.5)
tree.prune.pred = predict(prune.carseats, test)
mean((tree.prune.pred - test$Sales)^2)
prune.carseats = prune.tree(tree.carseats, best = 10)
plot(prune.carseats)
text(prune.carseats, pretty = 0, cex = 0.5)
tree.prune.pred = predict(prune.carseats, test)
mean((tree.prune.pred - test$Sales)^2)
train = sample(1:nrow(Carseats), nrow(Carseats) / 2)
test = Carseats[-train,]
#b) test MSE: 4.92
tree.carseats = tree(Sales~., Carseats, subset = train)
summary(tree.carseats)
tree.pred = predict(tree.carseats, test)
mean((tree.pred - test$Sales)^2)
plot(tree.carseats)
text(tree.carseats, pretty = 0, cex = 0.5)
#c)
#b) test MSE: 5.11
tree.carseats = tree(Sales~., Carseats, subset = train)
summary(tree.carseats)
tree.pred = predict(tree.carseats, test)
mean((tree.pred - test$Sales)^2)
plot(tree.carseats)
text(tree.carseats, pretty = 0, cex = 0.5)
#c)
cv.carseats = cv.tree(tree.carseats)
names(cv.carseats)
plot(cv.carseats$size, cv.carseats$dev, type = 'b')
# it looks like the best number of trees is 13, so we prune down!
prune.carseats = prune.tree(tree.carseats, best = 7)
plot(prune.carseats)
text(prune.carseats, pretty = 0, cex = 0.5)
tree.prune.pred = predict(prune.carseats, test)
mean((tree.prune.pred - test$Sales)^2)
prune.min = which.min(cv.carseats$dev)
points(prune.min, cv.carseats$dev[prune.min], col = "blue", cex = 2, pch = 20)
plot(cv.carseats$size, cv.carseats$dev, type = 'b')
prune.min = which.min(cv.carseats$dev)
points(prune.min, cv.carseats$dev[prune.min], col = "blue", cex = 2, pch = 20)
# it looks like the best number of trees is 13, so we prune down!
plot(cv.carseats$size, cv.carseats$dev, type = 'b')
par(mfrow = c(1,1))
#a) split into train and test
train = sample(1:nrow(Carseats), nrow(Carseats) / 2)
test = Carseats[-train,]
#b) test MSE: 5.11
tree.carseats = tree(Sales~., Carseats, subset = train)
summary(tree.carseats)
tree.pred = predict(tree.carseats, test)
mean((tree.pred - test$Sales)^2)
plot(tree.carseats)
text(tree.carseats, pretty = 0, cex = 0.5)
#c)
cv.carseats = cv.tree(tree.carseats)
names(cv.carseats)
plot(cv.carseats$size, cv.carseats$dev, type = 'b')
prune.min = which.min(cv.carseats$dev)
points(prune.min, cv.carseats$dev[prune.min], col = "blue", cex = 2, pch = 20)
cv.carseats = cv.tree(tree.carseats)
names(cv.carseats)
plot(cv.carseats$size, cv.carseats$dev, type = 'b')
# it looks like the best number of trees is 13, so we prune down!
prune.carseats = prune.tree(tree.carseats, best = 11)
plot(prune.carseats)
text(prune.carseats, pretty = 0, cex = 0.5)
tree.prune.pred = predict(prune.carseats, test)
mean((tree.prune.pred - test$Sales)^2)
#d) test MSE using Bagging: 2.374
tree.carseats = tree(Sales~., Carseats, subset = train)
summary(tree.carseats)
tree.pred = predict(tree.carseats, test)
mean((tree.pred - test$Sales)^2)
plot(tree.carseats)
text(tree.carseats, pretty = 0, cex = 0.5)
#c)
cv.carseats = cv.tree(tree.carseats)
names(cv.carseats)
plot(cv.carseats$size, cv.carseats$dev, type = 'b')
prune.carseats = prune.tree(tree.carseats, best = 15)
plot(prune.carseats)
text(prune.carseats, pretty = 0, cex = 0.5)
tree.prune.pred = predict(prune.carseats, test)
mean((tree.prune.pred - test$Sales)^2)
plot(cv.carseats$size, cv.carseats$dev, type = 'b')
# it looks like the best number of trees is 15, so we prune down!
# test MSE after pruning : 4.65
prune.carseats = prune.tree(tree.carseats, best = 15)
plot(prune.carseats)
prune.carseats = prune.tree(tree.carseats, best = 10)
plot(prune.carseats)
text(prune.carseats, pretty = 0, cex = 0.5)
tree.prune.pred = predict(prune.carseats, test)
mean((tree.prune.pred - test$Sales)^2)
tree.carseats = tree(Sales~., Carseats, subset = train)
summary(tree.carseats)
tree.pred = predict(tree.carseats, test)
mean((tree.pred - test$Sales)^2)
plot(tree.carseats)
text(tree.carseats, pretty = 0, cex = 0.5)
#c)
cv.carseats = cv.tree(tree.carseats)
names(cv.carseats)
plot(cv.carseats$size, cv.carseats$dev, type = 'b')
# it looks like the best number of trees is 15, so we prune down!
# test MSE after pruning : 4.65
prune.carseats = prune.tree(tree.carseats, best = 16)
plot(prune.carseats)
text(prune.carseats, pretty = 0, cex = 0.5)
tree.prune.pred = predict(prune.carseats, test)
mean((tree.prune.pred - test$Sales)^2)
set.seed(1)
par(mfrow = c(1,1))
#a) split into train and test
train = sample(1:nrow(Carseats), nrow(Carseats) / 2)
test = Carseats[-train,]
#b) test MSE: 5.25
tree.carseats = tree(Sales~., Carseats, subset = train)
summary(tree.carseats)
tree.pred = predict(tree.carseats, test)
mean((tree.pred - test$Sales)^2)
plot(tree.carseats)
text(tree.carseats, pretty = 0, cex = 0.5)
text(tree.carseats, pretty = 0, cex = 0.5)
#c)
cv.carseats = cv.tree(tree.carseats)
names(cv.carseats)
plot(cv.carseats$size, cv.carseats$dev, type = 'b')
# it looks like the best number of trees is 15, so we prune down!
prune.carseats = prune.tree(tree.carseats, best = 6)
plot(prune.carseats)
text(prune.carseats, pretty = 0, cex = 0.5)
tree.prune.pred = predict(prune.carseats, test)
mean((tree.prune.pred - test$Sales)^2)
set.seed(2)
length(colnames(Carseats))
bag.carseats = randomForest(Sales~., data = Carseats, subset = train, mtry = length(colnames(Carseats))-1, importance = T)
pred.bag = predict(bag.carseats, newdata = test)
mean((pred.bag - test$Sales)^2)
plot(pred.bag, test$Sales)
rf.carseats = randomForest(Sales~., data = Carseats, subset = train, mtry = 6, importance = T)
pred.rf = predict(rf.carseats, newdata = test)
mean((pred.rf - test$Sales)^2)
attach(OJ)
train = sample(1:nrow(OJ), 800)
test = OJ[-train,]
oj.tree = tree(Purchase~.-Buy, subset = train)
View(OJ)
oj.tree = tree(Purchase~.-Buy, OJ, subset = train)
oj.tree = tree(Purchase~., OJ, subset = train)
summary(oj.tree)
oj.tree
bag.oj = randomForest(Purchase~., data = OJ, subset = train, mtry = length(colnames(OJ))-1, importance = T)
pred.oj = predict(bag.oj, newdata = test)
mean((pred.oj - test$Purchase)^2)
pred.oj = predict(bag.oj, newdata = test, type = 'class')
table(pred.oj, test$Purchase)
1- (144+73)/length(test)
(144+73)/length(test)
(144+73)/nrow(test)
1-(144+73)/nrow(test)
text(oj.tree, pretty = 0, cex = 0.5)
plot(oj.tree)
text(oj.tree, pretty = 0, cex = 0.5)
tree.pred.oj = predict(oj.tree, newdata = test, type = 'class')
table(tree.pred.oj, test$Purchase)
1-(158+55)/nrow(test)
cv.oj = cv.tree(oj.tree)
plot(cv.oj$size, cv.oj$dev, type = 'b')
prune.oj = prune.tree(oj.tree, best = 6)
plot(prune.oj)
text(prune.oj, pretty = 0, cex = 0.5)
text(prune.oj, pretty = 0, cex = 0.5)
tree.prune.oj = predict(prune.oj, test)
table(tree.prune.oj, test$Purchase)
prune.oj = prune.tree(oj.tree, best = 6)
plot(prune.oj)
text(prune.oj, pretty = 0, cex = 0.5)
pred.prune.oj = predict(prune.oj, test)
table(pred.prune.oj, test$Purchase)
length(pred.prune.oj)
length(test)
pred.prune.oj = predict(prune.oj, newdata = test)
length(pred.prune.oj)
length(test)
pred.prune.oj = predict(prune.oj, test$Purchase)
length(pred.prune.oj)
length(test$Purchase)
pred.prune.oj = predict(prune.oj, test, type = 'class')
length(pred.prune.oj)
length(test)
table(pred.prune.oj, test$Purchase)
prune.oj = prune.tree(oj.tree, best = 6)
plot(prune.oj)
text(prune.oj, pretty = 0, cex = 0.5)
pred.prune.oj = predict(prune.oj, test, type = 'class')
table(pred.prune.oj, test$Purchase)
cv.oj = cv.tree(oj.tree)
plot(cv.oj$size, cv.oj$dev, type = 'b')
prune.oj = prune.tree(oj.tree, best = 8)
plot(prune.oj)
text(prune.oj, pretty = 0, cex = 0.5)
pred.prune.oj = predict(prune.oj, test, type = 'class')
table(pred.prune.oj, test$Purchase)
cv.oj = cv.tree(oj.tree)
plot(cv.oj$size, cv.oj$dev, type = 'b')
set.seed(1)
attach(OJ)
#a) split into training and testing
train = sample(1:nrow(OJ), 800)
test = OJ[-train,]
#b) error rate: 0.1713. 9 terminal nodes
oj.tree = tree(Purchase~., data = OJ, subset = train)
summary(oj.tree)
#c) tree object:  2) LoyalCH < 0.5036 363  419.400 MM ( 0.26446 0.73554 )
# loyalCH<0.5 is the split criterion. the number of obs in this branch is 363.
# It is an internal node because it doesn't have an asterisk, and has a deviance of 110.1.
# Less than 26% of obs in that branch take value of CH, and other 73% take value of MM
oj.tree
#d) plot: loyalCH is the most important node in this plot.
# the plot has 9 leaves and 5 terminal nodes
plot(oj.tree)
text(oj.tree, pretty = 0, cex = 0.5)
#e) tree MSE: 0.211
tree.pred.oj = predict(oj.tree, newdata = test, type = 'class')
table(tree.pred.oj, test$Purchase)
1-(158+55)/nrow(test)
#f and g and h) optimal tree and cv plot and error
cv.oj = cv.tree(oj.tree)
plot(cv.oj$size, cv.oj$dev, type = 'b')
# it looks like the best number of trees is 6, so we prune down!
prune.oj = prune.tree(oj.tree, best = 5)
plot(prune.oj)
text(prune.oj, pretty = 0, cex = 0.5)
pred.prune.oj = predict(prune.oj, test, type = 'class')
table(pred.prune.oj, test$Purchase)
1-(119+81)/nrow(test)
1-(147+62)/nrow(test)
#e) tree MSE: 0.22
tree.pred.oj = predict(oj.tree, newdata = test, type = 'class')
oj.tree = tree(Purchase~., data = OJ, subset = train)
plot(oj.tree)
text(oj.tree, pretty = 0, cex = 0.5)
#e) tree MSE: 0.22
tree.pred.oj = predict(oj.tree, newdata = test, type = 'class')
table(tree.pred.oj, test$Purchase)
1-(147+62)/nrow(test)
#f and g and h) optimal tree and cv plot and error
cv.oj = cv.tree(oj.tree)
plot(cv.oj$size, cv.oj$dev, type = 'b')
prune.oj = prune.tree(oj.tree, best = 4)
plot(prune.oj)
text(prune.oj, pretty = 0, cex = 0.5)
cv.oj = cv.tree(oj.tree, FUN = prune.misclass)
plot(cv.oj$size, cv.oj$dev, type = 'b')
prune.oj = prune.misclass(oj.tree, best = 5)
plot(prune.oj)
text(prune.oj, pretty = 0)
summary(tree.oj)
summary(oj.tree)
summary(prune.oj)
summary(prune.oj)
set.seed(1)
attach(OJ)
#a) split into training and testing
train = sample(1:nrow(OJ), 800)
test = OJ[-train,]
#b) error rate: 0.1713. 9 terminal nodes
oj.tree = tree(Purchase~., data = OJ, subset = train)
summary(oj.tree)
#c) tree object:  2) LoyalCH < 0.5036 363  419.400 MM ( 0.26446 0.73554 )
# loyalCH<0.5 is the split criterion. the number of obs in this branch is 363.
# It is an internal node because it doesn't have an asterisk, and has a deviance of 110.1.
# Less than 26% of obs in that branch take value of CH, and other 73% take value of MM
oj.tree
#d) plot: loyalCH is the most important node in this plot.
# the plot has 9 leaves and 5 terminal nodes
plot(oj.tree)
text(oj.tree, pretty = 0, cex = 0.5)
#e) tree MSE: 0.22
tree.pred.oj = predict(oj.tree, newdata = test, type = 'class')
table(tree.pred.oj, test$Purchase)
1-(147+62)/nrow(test)
#f and g and h) optimal tree and cv plot and error
cv.oj = cv.tree(oj.tree, FUN = prune.misclass)
plot(cv.oj$size, cv.oj$dev, type = 'b')
# it looks like the best number of trees is 5, so we prune down!
# i)
prune.oj = prune.misclass(oj.tree, best = 5)
plot(prune.oj)
text(prune.oj, pretty = 0)
#j) training unpruned error: 0.165
# training pruned error:
summary(oj.tree)
summary(prune.oj)
prune.oj = prune.misclass(oj.tree, best = 5)
plot(prune.oj)
text(prune.oj, pretty = 0)
cv.oj = cv.tree(oj.tree, FUN = prune.misclass)
plot(cv.oj$size, cv.oj$dev, type = 'b')
set.seed(1)
train = sample(1:nrow(OJ), 800)
test = OJ[-train,]
#b) error rate: 0.1713. 9 terminal nodes
oj.tree = tree(Purchase~., data = OJ, subset = train)
summary(oj.tree)
plot(oj.tree)
text(oj.tree, pretty = 0, cex = 0.5)
#e) tree MSE: 0.22
tree.pred.oj = predict(oj.tree, newdata = test, type = 'class')
table(tree.pred.oj, test$Purchase)
1-(147+62)/nrow(test)
#f and g and h) optimal tree and cv plot and error
cv.oj = cv.tree(oj.tree, FUN = prune.misclass)
plot(cv.oj$size, cv.oj$dev, type = 'b')
prune.oj = prune.misclass(oj.tree, best = 2)
plot(prune.oj)
text(prune.oj, pretty = 0)
#j) training unpruned error: 0.165
# training pruned error:
summary(oj.tree)
summary(prune.oj)
prune.pred = predict(prune.oj,test, type = "class")
table(prune.pred, test$Purchase)
1-(119+81)/nrow(test)
table(tree.pred.oj, test$Purchase)
1-(147+62)/nrow(test)
